{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data\n",
    "from dataset import SNPmarkersDataset\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from utils import format_batch\n",
    "from utils import train_DL_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, nlayers: int = 1, hidden_nodes: list[int] = [], dropout: float = 0):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        if dropout < 0 or dropout >= 1:\n",
    "            raise AttributeError(\"The dropout must be between 0 and 1\")\n",
    "\n",
    "        if nlayers < 1:\n",
    "            raise AttributeError(\"The number of layers must be greater or equal than one !\")\n",
    "        \n",
    "        if len(hidden_nodes) != nlayers - 1:\n",
    "            raise AttributeError(f\"Not enough hidden_nodes given, expected a list of length {nlayers - 1} but got one of {len(hidden_nodes)}\")\n",
    "\n",
    "        # Use a copy to avoid modifying the hyperparameter value for future runs\n",
    "        hidden_nodes_model = hidden_nodes.copy()\n",
    "        hidden_nodes_model.insert(0, 36304)\n",
    "        hidden_nodes_model.append(1)\n",
    "\n",
    "        self.model = nn.Sequential(*[LinearBlock(hidden_nodes_model[i], hidden_nodes_model[i + 1], dropout=dropout) for i in range(nlayers - 1)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(hidden_nodes_model[-2], hidden_nodes_model[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output_layer(self.dropout(self.model(x)))\n",
    "\n",
    "class LinearBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout = 0):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(in_features=input_size, out_features=output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return F.relu(self.fc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = 0.25\n",
    "N_LAYERS = 2\n",
    "HIDDEN_NODES = [1024]\n",
    "N_EPOCHS = 5\n",
    "SCHEDULER_STEP_SIZE = 20\n",
    "SCHEDULER_REDUCE_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SNPmarkersDataset(mode = \"local_train\", skip_check=True)\n",
    "validation_dataset = SNPmarkersDataset(mode = \"validation\", skip_check=True)\n",
    "selected_phenotypes = [\"ep_res\", \"de_res\", \"FESSEp_res\", \"FESSEa_res\"]\n",
    "\n",
    "train_dataset.set_phenotypes = selected_phenotypes\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = 4)\n",
    "        \n",
    "validation_dataset.set_phenotypes = selected_phenotypes\n",
    "validation_dataloader = data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, num_workers = 4)\n",
    "\n",
    "model = MLP(nlayers=N_LAYERS, hidden_nodes= HIDDEN_NODES, dropout= DROPOUT)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = SCHEDULER_STEP_SIZE, gamma = SCHEDULER_REDUCE_RATIO)\n",
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture : \n",
      " MLP(\n",
      "  (model): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (dropout): Dropout(p=0.25, inplace=False)\n",
      "      (fc): Linear(in_features=36304, out_features=1024, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (output_layer): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "Numbers of parameters: 37177345\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_DL_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphenotype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_phenotypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Session/Documents/Universite/Master 2/Master thesis/Code/utils.py:111\u001b[0m, in \u001b[0;36mtrain_DL_model\u001b[0;34m(model, optimizer, train_dataloader, validation_dataloader, n_epoch, criterion, scheduler, phenotype, log_wandb, initial_phenotype)\u001b[0m\n\u001b[1;32m    109\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m--> 111\u001b[0m     x,y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m    112\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    113\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "train_DL_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    validation_dataloader,\n",
    "    N_EPOCHS,\n",
    "    criterion,\n",
    "    scheduler=scheduler,\n",
    "    phenotype=selected_phenotypes,\n",
    "    log_wandb= False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
