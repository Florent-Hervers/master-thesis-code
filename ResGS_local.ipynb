{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data\n",
    "from dataset import SNPmarkersDataset\n",
    "import wandb\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_BN(nn.Module):\n",
    "    def __init__(self, input_size, nb_filter, kernel_size, strides=1, padding = 1):\n",
    "        super(Conv1d_BN, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_size, nb_filter, kernel_size, padding= padding, stride=strides)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(nb_filter)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class Res_Block(nn.Module):\n",
    "    def __init__(self, input_size, nb_filter, kernel_size, strides=1):\n",
    "        super(Res_Block, self).__init__()\n",
    "        self.block = Conv1d_BN(input_size,nb_filter=nb_filter,kernel_size=kernel_size,strides=strides)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.block(x)\n",
    "        return x\n",
    "\n",
    "class ResGSModel(nn.Module):\n",
    "\n",
    "    def __init__(self, nFilter, _KERNEL_SIZE, CHANNEL_FACTOR1, CHANNEL_FACTOR2, nlayers = 8):\n",
    "        super(ResGSModel, self).__init__()\n",
    "        self.input_block1 = Res_Block(1, nb_filter=nFilter, kernel_size=_KERNEL_SIZE, strides=1)\n",
    "        self.input_block2 = Res_Block(nFilter, nb_filter=nFilter, kernel_size=_KERNEL_SIZE, strides=1)\n",
    "        nFilter1 = int(nFilter * CHANNEL_FACTOR1)\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            *[nn.Sequential( \n",
    "                Conv1d_BN(int(nFilter * CHANNEL_FACTOR2**(i-1)), nb_filter=nFilter1, kernel_size=_KERNEL_SIZE, strides=2), \n",
    "                Conv1d_BN(nFilter1, nb_filter=int(nFilter * CHANNEL_FACTOR2**i), kernel_size=1, strides=1, padding=0), \n",
    "                Res_Block(int(nFilter * CHANNEL_FACTOR2**i), nb_filter=int(nFilter * CHANNEL_FACTOR2**i), kernel_size=_KERNEL_SIZE, strides=1), \n",
    "                Res_Block(int(nFilter * CHANNEL_FACTOR2**i), nb_filter=int(nFilter * CHANNEL_FACTOR2**i), kernel_size=_KERNEL_SIZE, strides=1),\n",
    "            )for i in range(1, nlayers + 1) ])\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            Conv1d_BN(int(nFilter * CHANNEL_FACTOR2**nlayers), nb_filter= 6400 // (int(nFilter * CHANNEL_FACTOR2**nlayers)), kernel_size=1, strides=1, padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((6400 // (int(nFilter * CHANNEL_FACTOR2**nlayers))) * (36304 // (2**nlayers)), 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set the number of channels to 1 as required by the conv1d layer\n",
    "        x = x.view(x.shape[0], 1, x.shape[1])\n",
    "        \n",
    "        x = self.input_block1(x)\n",
    "        x = self.input_block2(x)\n",
    "\n",
    "        x = self.layers(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = 0\n",
    "N_LAYERS = 2\n",
    "N_EPOCHS = 2\n",
    "SCHEDULER_STEP_SIZE = 200\n",
    "SCHEDULER_REDUCE_RATIO = 1\n",
    "KERNEL_SIZE = 3\n",
    "CHANNEL_FACTOR1 = 4\n",
    "CHANNEL_FACTOR2 = 1.1\n",
    "NFILTERS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SNPmarkersDataset(mode = \"local_train\", skip_check=True)\n",
    "validation_dataset = SNPmarkersDataset(mode = \"validation\", skip_check=True)\n",
    "selected_phenotypes = [\"ep_res\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture : \n",
      " ResGSModel(\n",
      "  (input_block1): Res_Block(\n",
      "    (block): Conv1d_BN(\n",
      "      (conv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu): ReLU()\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (input_block2): Res_Block(\n",
      "    (block): Conv1d_BN(\n",
      "      (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu): ReLU()\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layers): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d_BN(\n",
      "        (conv): Conv1d(32, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "        (relu): ReLU()\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): Conv1d_BN(\n",
      "        (conv): Conv1d(128, 35, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "        (bn): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): Res_Block(\n",
      "        (block): Conv1d_BN(\n",
      "          (conv): Conv1d(35, 35, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (relu): ReLU()\n",
      "          (bn): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Res_Block(\n",
      "        (block): Conv1d_BN(\n",
      "          (conv): Conv1d(35, 35, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (relu): ReLU()\n",
      "          (bn): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv1d_BN(\n",
      "        (conv): Conv1d(35, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "        (relu): ReLU()\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): Conv1d_BN(\n",
      "        (conv): Conv1d(128, 38, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "        (bn): BatchNorm1d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): Res_Block(\n",
      "        (block): Conv1d_BN(\n",
      "          (conv): Conv1d(38, 38, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (relu): ReLU()\n",
      "          (bn): BatchNorm1d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Res_Block(\n",
      "        (block): Conv1d_BN(\n",
      "          (conv): Conv1d(38, 38, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (relu): ReLU()\n",
      "          (bn): BatchNorm1d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Conv1d_BN(\n",
      "      (conv): Conv1d(38, 168, kernel_size=(1,), stride=(1,))\n",
      "      (relu): ReLU()\n",
      "      (bn): BatchNorm1d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=1524768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Numbers of parameters: 1587528\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for phenotype in selected_phenotypes:\n",
    "    train_dataset.set_phenotypes = phenotype\n",
    "    validation_dataset.set_phenotypes = phenotype\n",
    "\n",
    "    train_dataloader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = 4)\n",
    "    validation_dataloader = data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, num_workers = 4)\n",
    "\n",
    "    model = ResGSModel(NFILTERS, KERNEL_SIZE, CHANNEL_FACTOR1, CHANNEL_FACTOR2, N_LAYERS)\n",
    "    print(f\"Model architecture : \\n {model}\")\n",
    "    print(f\"Numbers of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criteron = torch.nn.L1Loss()\n",
    "    model.to(device)\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_loss = []\n",
    "        model.train()\n",
    "        for x,y in train_dataloader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            y = y.view(-1,1)\n",
    "            loss = criteron(output, y)\n",
    "            train_loss.append(loss.cpu().detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Finished training for epoch {epoch} for {phenotype}.\")\n",
    "\n",
    "        val_loss = []\n",
    "        predicted = []\n",
    "        target = []\n",
    "        model.eval()\n",
    "        for x,y in validation_dataloader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            y = y.view(-1,1)\n",
    "            loss = criteron(output, y)\n",
    "            val_loss.append(loss.cpu().detach())\n",
    "            if len(predicted) == 0:\n",
    "                predicted = output.cpu().detach()\n",
    "                target = y.cpu().detach()\n",
    "            else:\n",
    "                predicted = np.concatenate((predicted, output.cpu().detach()), axis = 0)\n",
    "                target = np.concatenate((target, y.cpu().detach()), axis = 0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Resize the vectors to be accepted in the pearsonr function\n",
    "        predicted = predicted.reshape((predicted.shape[0],))\n",
    "        target = target.reshape((target.shape[0],))\n",
    "\n",
    "        print(f\"Validation step for epoch {epoch} for {phenotype} finished! Correlation: {pearsonr(predicted, target)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
